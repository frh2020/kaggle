{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Train-on-Google-Cloud-ML-Engine\">Train, deploy, predict on Google Cloud ML Engine</h1>\n",
    "\n",
    "<p>tags: kaggle, digit, mnist, cnn, esitmator, google cloud, ml-engline, ai-platform, submit, train&nbsp;&nbsp;</p>\n",
    "\n",
    "<p>read this doc to start off&nbsp;</p>\n",
    "\n",
    "<p><a href=\"https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-training-prediction#tensorboard-local\" target=\"_blank\">https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-training-prediction#tensorboard-local</a></p>\n",
    "\n",
    "<h2 id=\"modification-from-local-run\">modification from local run</h2>\n",
    "\n",
    "<ol>\n",
    "\t<li>import gcsfs in this notebook</li>\n",
    "\t<li>put &#39;gcsfs&#39;&nbsp;in REQUIRED_PACKAGE in setup.py</li>\n",
    "\t<li>change &#39;export&#39; directory name to just the name no &#39;/\\&#39;</li>\n",
    "</ol>\n",
    "\n",
    "<h2 id=\"Recommended-project-structure\">Recommended project structure</h2>\n",
    "\n",
    "<p><img src=\"recommended-project-structure.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"to-do-list-before-submit-the-job\">to-do list before submit the job</h2>\n",
    "\n",
    "<ol>\n",
    "\t<li>get or set project id from gcp console</li>\n",
    "\t<li>create a bucket and folders, then upload training data</li>\n",
    "</ol>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import gcsfs\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import json, codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT = \"_____\" # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"_____\" # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "TFVERSION = \"1.13\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = TFVERSION  # Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gcloud auth list\n",
    "!gcloud config set project $PROJECT\n",
    "!gcloud config set compute/region $REGION\n",
    "!gcloud config list project\n",
    "#!gcloud compute instances list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Train-locally\">Train locally (for testing)</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR='trained_test'\n",
    "INPDIR='..\\data'\n",
    "shutil.rmtree(path = OUTDIR, ignore_errors = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line won't run until this nb is halted and closed. so instead, run the command in a terminal\n",
    "#!gcloud ai-platform local train \\\n",
    "#--module-name=trainer.task \\\n",
    "#--package-path=trainer \\\n",
    "#-- \\\n",
    "#--output_dir=$OUTDIR \\\n",
    "#--input_dir=$INPDIR \\\n",
    "#--epochs=2 --learning_rate=0.001 --batch_size=100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this command lines in a terminal to train model locally \n",
    "<pre>\n",
    "cd .\\Desktop\\study\\kaggle\\project_digit\\train_01\\\n",
    "</pre>\n",
    "<pre>\n",
    "gcloud ai-platform local train --module-name=trainer.task --package-path=trainer --  --output_dir=trained_test --input_dir=..\\data --epochs=2 --learning_rate=0.001 --batch_size=100\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Train-on-Cloud-ML-Engine\">Train on Cloud ML Engine</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OUTDIR='gs://'+BUCKET+'/train_01'\n",
    "INPDIR='gs://'+BUCKET+'/digit/data'\n",
    "\n",
    "\n",
    "print(\"OUTDIR: \",OUTDIR)\n",
    "print(\"INPDIR: \",INPDIR)\n",
    "print(\"REGION: \", REGION)\n",
    "\n",
    "print(\"BUCKET: \", BUCKET)\n",
    "print(\"TFVERSION: \", TFVERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gsutil -m rm -rf $OUTDIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOBNAME='kaggle_digit_01_'+datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(\"JOBNAME: \", JOBNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: kaggle_digit_01_20190828_145418\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [kaggle_digit_01_20190828_145418] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe kaggle_digit_01_20190828_145418\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs kaggle_digit_01_20190828_145418\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "--region=$REGION \\\n",
    "--module-name=trainer.task \\\n",
    "--package-path=trainer \\\n",
    "--job-dir=$OUTDIR \\\n",
    "--staging-bucket=gs://$BUCKET \\\n",
    "--scale-tier=CUSTOM \\\n",
    "--master-machine-type=n1-standard-4 \\\n",
    "--runtime-version=$TFVERSION \\\n",
    "-- \\\n",
    "--output_dir=$OUTDIR \\\n",
    "--input_dir=$INPDIR \\\n",
    "--epochs=2 --learning_rate=0.001 --batch_size=100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"OUTDIR: \",OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Monitoring-training-with-TensorBoard\">Monitoring training with TensorBoard</h2>\n",
    "\n",
    "<ol>\n",
    "\t<li>open a cloud shell and run the following (replace OUTDIR with actual gs folder)\n",
    "\t<pre>\n",
    "tensorboard --logdir=OUTDIR --port=8080   </pre>\n",
    "\t</li>\n",
    "\t<li>Select &quot;Preview on port 8080&quot; from the Web Preview menu at the top of the command line.</li>\n",
    "\t<li>in cloud cell window hit ctrl-c to exit.&nbsp;</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gsutil ls gs://$BUCKET/train_01/export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='kaggle_digit_cnn'\n",
    "MODEL_VERSION=\"t01\"\n",
    "MODEL_LOCATION=\"gs://______/train_01/export/1567022286/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gcloud ai-platform versions delete $MODEL_VERSION --model $MODEL_NAME\n",
    "#!gcloud ai-platform models delete $MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!gcloud ai-platform models create $MODEL_NAME --regions $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "Creating version (this might take a few minutes)......\n",
      ".........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform versions create $MODEL_VERSION --model $MODEL_NAME --origin $MODEL_LOCATION --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input dataset (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json file from test iamges for predict\n",
    "\n",
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "\n",
    "#### input test data\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test_images = test.to_numpy().astype('float32')/255.0\n",
    "test_images = test_images.reshape(-1,HEIGHT,WIDTH)\n",
    "\n",
    "# convert all data \n",
    "\n",
    "jsondata = {\"image\": test_images.tolist()}\n",
    "\n",
    "#json.dump(jsondata, codecs.open(\"../data/test.json\", \"w\", encoding = \"utf-8\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGwAAABsCAYAAACPZlfNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADp0lEQVR4nO2dPUsrQRiFN3JBxcImRSrBJlqoIPkHBsQuIITYCdqIdhaWARsrQSwihGDS20SQkDQRG7X2AwxpRBIFITYiFoLmdu+dd29CvjZmz3Ke6qwzzA4+zsxmM4O+er1uERyGBt0B0hkUBgaFgUFhYFAYGH9alPMRcnD4Gv2QIwwMCgODwsCgMDAoDAwKA4PCwKAwMCgMDAoDg8LAoDAwKAwMCgODwsCgMDAoDAwKA4PCwKAwMCgMDAoDg8LAaLUv0fWUSiXJ09PTkn9+flS9z89PyY+Pj6rs4uKiYduRSERdT0xMdNtNx+AIA4PCwPC1ONDnuq3am5ub6vr6+lpyIpGQfHV1peodHh5Krlarqszna7gr2pqdnVXXNzc3nXW2N7hV2wtQGBgUBgbEGpZOpyXH43FV9vz8LHlxcVHy2NiYqre8vNy0/be3N8lHR0eSy+Wyqre2tib5+Pi4Vbd7hWuYF6AwMCCmxFqtJnlvb0+V7ezsSB4fH5c8Ojra1b3u7+8lz83NNa1nf5PSBzglegEKA6Ptl7/2F6aTk5OOd8bk9fVV8v7+vuRgMKjqBQIBR+/79fXlaHtOwxEGBoWBQWFgtL2G9XvNsrO+vi65WCxKrlQqfb2vuV7a+e3fQSM4wsCgMDBcs6fj/f1dXZvTTzablez3+x2/t7kv5OzsrGk9+0ebQcARBgaFgeGaKdHcj2FZlpVKpSSvrq46ei/73oyVlRXJHx8fkqemplS98/NzR/vRDRxhYFAYGBQGhmu+wLSvF0ND//6WHh4eem7ffHSPxWKq7O7uTvLIyIjky8tLVW9+fr7nfnQAv8D0AhQGxkAf681p6uXlRZWdnp523J65XW13d1eVZTIZyeaju2XpUym5XE7yzMxMx33oNxxhYFAYGBQGhmteTdkxT0WGw2HJ9vVne3tbcqFQkGw/UjQ8PCx5Y2NDlW1tbUl247plwhEGBoWB4do3HU9PT5IXFhYk397eqnr2jwPN2js4OJC8tLTUdT9/Eb7p8AIUBoZrnhJDoZC6Ng/T5fP5ttowD+0lk0lV1o+9IIOAIwwMCgODwsBwzWP99/e3uj45OZFsvoW39zcajUp24gSmi+BjvRegMDBcMyWS/+CU6AUoDAwKA4PCwKAwMCgMDAoDg8LAoDAwKAwMCgODwsCgMDAoDAwKA4PCwKAwMCgMDAoDg8LAoDAwKAwMCgOj1XGjxv8ckgwMjjAwKAwMCgODwsCgMDAoDIy/jS3Zb6mPpQEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert same examples for testing\n",
    "IMGNO = [3]\n",
    "jsondata = {\"image\": test_images[IMGNO].reshape([HEIGHT,WIDTH]).tolist()}\n",
    "json.dump(jsondata, codecs.open(\"../data/test_1.json\", \"w\", encoding = \"utf-8\"))\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "i=0\n",
    "for IMG in IMGNO:  \n",
    "    i+=1\n",
    "    plt.subplot(1, 10, i)\n",
    "    plt.imshow(test_images[IMG].reshape(HEIGHT, WIDTH), cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local predict (Not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If the signature defined in the model is not serving_default then you must specify it via --signature-name flag, otherwise the command may fail.\n",
      "ERROR: (gcloud.ai-platform.local.predict) Something has gone really wrong; we can't find a valid Python executable on your PATH.\n"
     ]
    }
   ],
   "source": [
    "# this maybe a cloud sdk not supporting python 2.7 on windows..\n",
    "!gcloud ai-platform local predict \\\n",
    "--model-dir=.\\trained_test\\export\\1567026070\\ \\\n",
    "--json-instances=test_1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send data to the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='kaggle_digit_cnn'\n",
    "MODEL_VERSION=\"t01\"\n",
    "JSON_DATA=\"../data/test_1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS_IDS  PROBABILITIES\n",
      "0          [0.7255470156669617, 0.000783188792411238, 0.045175887644290924, 0.0027230193372815847, 0.00012076550774509087, 0.0006411413196474314, 0.00045932986540719867, 0.013404745608568192, 0.022294849157333374, 0.1888500154018402]\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict \\\n",
    "    --model=$MODEL_NAME \\\n",
    "    --version=$MODEL_VERSION \\\n",
    "    --json-instances=$JSON_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Summary\">Summary</h2>\n",
    "\n",
    "<p>This is a basic flow for training, deploying model on GCP, and perform a prediction. it trains only 2 epochs and predict 1 image. finally run will be full strength.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<h2 id=\"Next-steps\">Next steps</h2>\n",
    "\n",
    "<ol>\n",
    "\t<li>batch prediction</li>\n",
    "\t<li>data augmentation with iterator</li>\n",
    "\t<li>replace&nbsp;tf.contrib.layers.optimize_loss&nbsp;since it will be deprecated in tf2.0, new method should also implement adaptive ir</li>\n",
    "</ol>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
