{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"MNIST-Image-Classification \">MNIST Image Classification&nbsp;</h1>\n",
    "\n",
    "<p>CNN model&nbsp;on MNIST using Estimator</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>major steps:</p>\n",
    "\n",
    "<ol>\n",
    "\t<li>image input from local data csv</li>\n",
    "\t<li>image reshape&nbsp;to [-1, HEIGHT, WIDTH,&nbsp; 1],&nbsp;serving_input_fn need to expand dim in feature</li>\n",
    "\t<li>label converted one_hot, use softmax cross entrocpy for loss&nbsp;</li>\n",
    "\t<li>build from keras and transform to estimator</li>\n",
    "</ol>\n",
    "\n",
    "<p>&nbsp;</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train.drop(labels = [\"label\"],axis = 1)\n",
    "train_labels = train[\"label\"]\n",
    "\n",
    "train_images = train_images.to_numpy()/255.0\n",
    "test_images = test.to_numpy()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "NCLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 50\n",
    "plt.figure(figsize=(20,5))\n",
    "for IMGNO in range(i,i+20):  \n",
    "    plt.subplot(2, 10, IMGNO-i+1)\n",
    "    plt.imshow(train_images[IMGNO].reshape(HEIGHT, WIDTH), cmap=plt.cm.binary)\n",
    "    plt.title(\"label = %d\" % train_labels[IMGNO],y=0.9)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1,HEIGHT,WIDTH,1)\n",
    "test_images = test_images.reshape(-1,HEIGHT,WIDTH,1)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes = NCLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train_images, train_labels, test_size = 0.1)\n",
    "\n",
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.10,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a CNN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "\n",
    "    X = tf.keras.layers.Input(shape = (HEIGHT, WIDTH, 1))\n",
    "\n",
    "    c1 = tf.keras.layers.Conv2D(filters = 16, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu')(X)   # shape = (batch_size, HEIGHT, WIDTH, nfil1)\n",
    "\n",
    "    #c1 = tf.keras.layers.BatchNormalization()(c1)          \n",
    "                      \n",
    "    p1 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(c1)                                                       # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(filters = 32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu')(p1)    # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil2)\n",
    "    \n",
    "    #c2 = tf.keras.layers.BatchNormalization()(c2)   \n",
    "\n",
    "    p2 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(c2)                                                        # shape = (batch_size, HEIGHT // 4, WIDTH // 4, nfil2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(p2)    # shape = (batch_size, HEIGHT // 2, WIDTH // 2, nfil2)\n",
    "\n",
    "    #c3 = tf.keras.layers.BatchNormalization()(c3)      \n",
    "\n",
    "    p3 = tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2)(c3)                                                      # shape = (batch_size, HEIGHT // 4, WIDTH // 4, nfil2)\n",
    "\n",
    "    p3 = tf.keras.layers.Flatten()(p3)                                                                               # shape = (batch_size, HEIGHT // 4 * WIDTH // 4 * nfil2)\n",
    "\n",
    "    h3 = tf.keras.layers.Dense(units = 64, activation = 'relu')(p3)\n",
    "    \n",
    "    ##h3 = keras.layers.BatchNormalization()(h3)               \n",
    "    \n",
    "    h3 = tf.keras.layers.Dropout(rate = 0.25)(h3)\n",
    "\n",
    "    output = tf.keras.layers.Dense(units = NCLASSES, activation = 'softmax')(h3)\n",
    "  \n",
    "    #output = keras.layers.BatchNormalization()(output)\n",
    "\n",
    "    model = tf.keras.Model(inputs=X, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams, X_train, X_val, Y_train, Y_val):\n",
    "    \n",
    "    model = get_model()\n",
    "    model.summary()\n",
    "    \n",
    "    estimator = tf.keras.estimator.model_to_estimator(keras_model=model, \n",
    "                                                      model_dir=output_dir)\n",
    "\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = X_train,\n",
    "        y = Y_train,\n",
    "        batch_size = hparams['batch_size'],\n",
    "        num_epochs = hparams['epochs'],\n",
    "        shuffle = True,\n",
    "        queue_capacity = 5000\n",
    "    )\n",
    "\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = X_val,\n",
    "        y = Y_val,\n",
    "        batch_size = hparams['batch_size'],\n",
    "        num_epochs = 1,\n",
    "        shuffle = False,\n",
    "        queue_capacity = 5000 #TODO   \n",
    "    )\n",
    "    \n",
    " \n",
    "    estimator.train(input_fn=train_input_fn)\n",
    "    \n",
    "    eval_results = estimator.evaluate(input_fn=eval_input_fn)\n",
    "    \n",
    "    \n",
    "\n",
    "#   \n",
    "#    exporter = tf.estimator.LatestExporter(name = \"exporter\", serving_input_receiver_fn = serving_input_fn)\n",
    "#\n",
    "#    tf.estimator.train_and_evaluate(estimator = estimator, train_spec = train_spec, eval_spec = eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Input functions for training, evaluation, and predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "\n",
    "    feature_placeholders = tf.placeholder(dtype = tf.float32, shape = [None, HEIGHT, WIDTH])\n",
    "\n",
    "    features = tf.expand_dims(input = feature_placeholders[\"image\"], axis = -1)\n",
    "    return tf.estimator.export.ServingInputReceiver(features =  features, receiver_tensors =  feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\huangf\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\huangf\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 69,322\n",
      "Trainable params: 69,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From C:\\Users\\huangf\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'mnist\\\\learned_v02', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D2A5417278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\huangf\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\huangf\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='mnist\\\\learned_v02\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('mnist\\\\learned_v02\\\\keras\\\\keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: conv2d/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: conv2d_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_12; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_13; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_14; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_15; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_16; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_17; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_18; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_19; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_20; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_21; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_22; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_23; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_24; prev_var_name: Unchanged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_25; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_26; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_27; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_28; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_29; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\huangf\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into mnist\\learned_v02\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3133626, step = 1\n",
      "INFO:tensorflow:global_step/sec: 7.56129\n",
      "INFO:tensorflow:loss = 0.4425235, step = 101 (13.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.67907\n",
      "INFO:tensorflow:loss = 0.22338372, step = 201 (14.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.17708\n",
      "INFO:tensorflow:loss = 0.11469065, step = 301 (13.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.29021\n",
      "INFO:tensorflow:loss = 0.24391027, step = 401 (13.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.49591\n",
      "INFO:tensorflow:loss = 0.08174207, step = 501 (13.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.52234\n",
      "INFO:tensorflow:loss = 0.077174366, step = 601 (13.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.62085\n",
      "INFO:tensorflow:loss = 0.16259174, step = 701 (13.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.56458\n",
      "INFO:tensorflow:loss = 0.106257915, step = 801 (13.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.42627\n",
      "INFO:tensorflow:loss = 0.06191139, step = 901 (13.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.07349\n",
      "INFO:tensorflow:loss = 0.04030156, step = 1001 (14.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.37501\n",
      "INFO:tensorflow:loss = 0.0602565, step = 1101 (13.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.39092\n",
      "INFO:tensorflow:loss = 0.08627312, step = 1201 (13.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.39698\n",
      "INFO:tensorflow:loss = 0.081505194, step = 1301 (13.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.67567\n",
      "INFO:tensorflow:loss = 0.12745313, step = 1401 (13.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50419\n",
      "INFO:tensorflow:loss = 0.028035507, step = 1501 (13.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5309\n",
      "INFO:tensorflow:loss = 0.12845473, step = 1601 (13.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.38909\n",
      "INFO:tensorflow:loss = 0.008380316, step = 1701 (13.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53119\n",
      "INFO:tensorflow:loss = 0.046239767, step = 1801 (13.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.46097\n",
      "INFO:tensorflow:loss = 0.046878133, step = 1901 (13.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.68489\n",
      "INFO:tensorflow:loss = 0.015191993, step = 2001 (13.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.40348\n",
      "INFO:tensorflow:loss = 0.08209442, step = 2101 (13.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.42564\n",
      "INFO:tensorflow:loss = 0.091240376, step = 2201 (13.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.32438\n",
      "INFO:tensorflow:loss = 0.0150717255, step = 2301 (13.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.46097\n",
      "INFO:tensorflow:loss = 0.013605069, step = 2401 (13.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.48425\n",
      "INFO:tensorflow:loss = 0.029263465, step = 2501 (13.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.61154\n",
      "INFO:tensorflow:loss = 0.016944338, step = 2601 (13.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.51351\n",
      "INFO:tensorflow:loss = 0.10205422, step = 2701 (13.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.41774\n",
      "INFO:tensorflow:loss = 0.01832739, step = 2801 (13.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5291\n",
      "INFO:tensorflow:loss = 0.030120183, step = 2901 (13.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53496\n",
      "INFO:tensorflow:loss = 0.037857376, step = 3001 (13.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50057\n",
      "INFO:tensorflow:loss = 0.006077019, step = 3101 (13.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.69412\n",
      "INFO:tensorflow:loss = 0.03972203, step = 3201 (12.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.43497\n",
      "INFO:tensorflow:loss = 0.007820549, step = 3301 (13.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5272\n",
      "INFO:tensorflow:loss = 0.008863924, step = 3401 (13.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.28686\n",
      "INFO:tensorflow:loss = 0.04186176, step = 3501 (13.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.40059\n",
      "INFO:tensorflow:loss = 0.0075198696, step = 3601 (13.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.34961\n",
      "INFO:tensorflow:loss = 0.0032201472, step = 3701 (13.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.64672\n",
      "INFO:tensorflow:loss = 0.018240824, step = 3801 (13.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50186\n",
      "INFO:tensorflow:loss = 0.0020085825, step = 3901 (13.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.3728\n",
      "INFO:tensorflow:loss = 0.046872072, step = 4001 (13.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53119\n",
      "INFO:tensorflow:loss = 0.015422862, step = 4101 (13.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.52943\n",
      "INFO:tensorflow:loss = 0.0057424535, step = 4201 (13.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53797\n",
      "INFO:tensorflow:loss = 0.013684442, step = 4301 (13.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.56981\n",
      "INFO:tensorflow:loss = 0.07771926, step = 4401 (13.195 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4469 into mnist\\learned_v02\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.66824\n",
      "INFO:tensorflow:loss = 0.046597324, step = 4501 (15.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5047\n",
      "INFO:tensorflow:loss = 0.016146595, step = 4601 (13.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50609\n",
      "INFO:tensorflow:loss = 0.015474657, step = 4701 (13.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.48902\n",
      "INFO:tensorflow:loss = 0.017634682, step = 4801 (13.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50391\n",
      "INFO:tensorflow:loss = 0.0373138, step = 4901 (13.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.62085\n",
      "INFO:tensorflow:loss = 0.0045477827, step = 5001 (13.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.60207\n",
      "INFO:tensorflow:loss = 0.006135809, step = 5101 (13.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.51008\n",
      "INFO:tensorflow:loss = 0.031482194, step = 5201 (13.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53119\n",
      "INFO:tensorflow:loss = 0.0040304456, step = 5301 (13.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.40916\n",
      "INFO:tensorflow:loss = 0.012411411, step = 5401 (13.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.46949\n",
      "INFO:tensorflow:loss = 0.07260254, step = 5501 (13.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.60234\n",
      "INFO:tensorflow:loss = 0.038859874, step = 5601 (13.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5668\n",
      "INFO:tensorflow:loss = 0.007558915, step = 5701 (13.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.42255\n",
      "INFO:tensorflow:loss = 0.0073128, step = 5801 (13.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55787\n",
      "INFO:tensorflow:loss = 0.013684777, step = 5901 (13.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53946\n",
      "INFO:tensorflow:loss = 0.010152402, step = 6001 (13.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55628\n",
      "INFO:tensorflow:loss = 0.010812694, step = 6101 (13.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.08524\n",
      "INFO:tensorflow:loss = 0.019875852, step = 6201 (14.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55011\n",
      "INFO:tensorflow:loss = 0.0010672532, step = 6301 (13.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53626\n",
      "INFO:tensorflow:loss = 0.01458967, step = 6401 (13.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5464\n",
      "INFO:tensorflow:loss = 0.0070046065, step = 6501 (13.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5668\n",
      "INFO:tensorflow:loss = 0.0045131044, step = 6601 (13.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.51958\n",
      "INFO:tensorflow:loss = 0.08345676, step = 6701 (13.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.6204\n",
      "INFO:tensorflow:loss = 0.01325509, step = 6801 (13.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5119\n",
      "INFO:tensorflow:loss = 0.0011355893, step = 6901 (13.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.56652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.006980445, step = 7001 (13.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.54895\n",
      "INFO:tensorflow:loss = 0.008534533, step = 7101 (13.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55787\n",
      "INFO:tensorflow:loss = 0.020243654, step = 7201 (13.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.51047\n",
      "INFO:tensorflow:loss = 0.027749307, step = 7301 (13.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.61053\n",
      "INFO:tensorflow:loss = 0.0013114085, step = 7401 (13.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.54895\n",
      "INFO:tensorflow:loss = 0.015514713, step = 7501 (13.106 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7561 into mnist\\learned_v02\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.005686195.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\huangf\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:363: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Starting evaluation at 2019-08-18T18:13:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\huangf\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from mnist\\learned_v02\\model.ckpt-7561\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-08-18-18:13:40\n",
      "INFO:tensorflow:Saving dict for global step 7561: categorical_accuracy = 0.9902381, global_step = 7561, loss = 0.046653934\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7561: mnist\\learned_v02\\model.ckpt-7561\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = \"mnist\\learned_v02\"\n",
    "shutil.rmtree(path = OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "\n",
    "hparams = {\"epochs\": 20, \"batch_size\": 100, \"learning_rate\": 0.001, \"batch_norm\":0 }\n",
    "\n",
    "train_and_evaluate(OUTDIR, hparams, X_train, X_val, Y_train, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_spec = {\n",
    "#    input_name: tf.FixedLenFeature(shape=[784], dtype=np.float32)\n",
    "#}\n",
    "#serving_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "#export_dir = classifier.export_savedmodel(export_dir_base=\"models/export\", \n",
    "#                            serving_input_receiver_fn=serving_fn)\n",
    "#export_dir = export_dir.decode(\"utf8\")\n",
    "\n",
    "#predict_results = est_catvsdog.predict(\n",
    "#    input_fn=lambda: imgs_input_fn(test_files[:10], \n",
    "#                                   labels=None, \n",
    "#                                   perform_shuffle=False,\n",
    "#                                   batch_size=10))\n",
    "#predict_logits = []\n",
    "#for prediction in predict_results:\n",
    "#    predict_logits.append(prediction['dense_2'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>results comparison</p>\n",
    "\n",
    "<table align=\"left\" border=\"2\" cellpadding=\"1\" cellspacing=\"1\" style=\"width: 500px\">\n",
    "\t<thead>\n",
    "\t\t<tr>\n",
    "\t\t\t<th scope=\"col\">kaggle score</th>\n",
    "\t\t\t<th scope=\"col\">rank</th>\n",
    "\t\t\t<th scope=\"col\">data augmentation</th>\n",
    "\t\t\t<th scope=\"col\">model build</th>\n",
    "\t\t\t<th scope=\"col\">epochs</th>\n",
    "\t\t</tr>\n",
    "\t</thead>\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>0.99057</td>\n",
    "\t\t\t<td>&nbsp;</td>\n",
    "\t\t\t<td>No</td>\n",
    "\t\t\t<td>keras</td>\n",
    "\t\t\t<td>20</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>0.99024</td>\n",
    "\t\t\t<td>&nbsp;</td>\n",
    "\t\t\t<td>No</td>\n",
    "\t\t\t<td>keras to estimator</td>\n",
    "\t\t\t<td>20</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>0.99257</td>\n",
    "\t\t\t<td>910</td>\n",
    "\t\t\t<td>Yes</td>\n",
    "\t\t\t<td>keras</td>\n",
    "\t\t\t<td>20</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>0.99457</td>\n",
    "\t\t\t<td>655</td>\n",
    "\t\t\t<td>Yes</td>\n",
    "\t\t\t<td>keras</td>\n",
    "\t\t\t<td>30</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"notes\">notes</h2>\n",
    "\n",
    "<p>when building keras model use&nbsp;<em>model = tf.keras.Model(inputs=X, outputs=output)</em>. Do NOT use <em>keras.Model</em> which gives the follow error&nbsp;</p>\n",
    "\n",
    "<pre>\n",
    "ValueError: (&#39;Expected `model` argument to be a `Model` instance, got &#39;, &lt;keras.engine.training.Model object at 0x000002C3A950F2B0&gt;)</pre>\n",
    "\n",
    "<p>actually, for consistency and avoiding incompatible issues, use <em>tf.keras</em> all the way.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Next-steps\">Next steps</h2>\n",
    "\n",
    "<ol>\n",
    "\t<li>impletment prediction, collect log info, save model</li>\n",
    "\t<li>data augmentation and learning rate</li>\n",
    "\t<li>create GCP training files</li>\n",
    "\t<li>ensemble method</li>\n",
    "\t<li>TF2</li>\n",
    "</ol>\n",
    "\n",
    "<h2 id=\"Credits\">Credits</h2>\n",
    "\n",
    "<p><a href=\"https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/08_image/mnistmodel/trainer/model.py\" target=\"_blank\">https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/08_image/mnistmodel/trainer/model.py</a></p>\n",
    "\n",
    "<p><a href=\"https://www.tensorflow.org/tutorials/estimators/cnn\" target=\"_blank\">https://www.tensorflow.org/tutorials/estimators/cnn</a></p>\n",
    "\n",
    "<p><a href=\"https://www.tensorflow.org/guide/estimators\" target=\"_blank\">https://www.tensorflow.org/guide/estimators</a></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>&nbsp;</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
